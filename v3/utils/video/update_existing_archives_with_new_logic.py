#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ—¢å­˜ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ã—ã„æ™‚åˆ»åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã§å†æ›´æ–°

- DB ã«ç™»éŒ²æ¸ˆã¿ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆcontent_type='archive'ï¼‰ã‚’å–å¾—
- YouTube API ã‹ã‚‰æœ€æ–°æƒ…å ±ã‚’å–å¾—
- æ–°ã—ã„åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆactualEndTime vs publishedAtï¼‰ã‚’é©ç”¨
- DB ã‚’æ›´æ–°
"""

import sqlite3
import os
import logging
from datetime import datetime, timezone
from pathlib import Path

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

DB_PATH = "data/video_list.db"

def convert_utc_to_jst(utc_datetime_str: str) -> str:
    """UTC ISO 8601 ã‚’ JST ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šå½¢å¼ã«å¤‰æ›"""
    try:
        from datetime import timedelta
        # "Z" ã¾ãŸã¯ "+00:00" ã‚’å‡¦ç†
        utc_time = datetime.fromisoformat(utc_datetime_str.replace('Z', '+00:00'))
        jst_time = utc_time.astimezone(timezone(timedelta(hours=9)))
        return jst_time.strftime('%Y-%m-%d %H:%M:%S')
    except Exception as e:
        logger.error(f"âŒ UTCâ†’JST å¤‰æ›ã‚¨ãƒ©ãƒ¼: {utc_datetime_str} - {e}")
        return utc_datetime_str


def get_archive_api_details(video_id: str, api_key: str) -> dict:
    """YouTube API ã‹ã‚‰ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–è©³ç´°ã‚’å–å¾—"""
    try:
        import requests
        url = "https://www.googleapis.com/youtube/v3/videos"
        params = {
            "part": "snippet,liveStreamingDetails",
            "id": video_id,
            "key": api_key
        }
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()

        data = response.json()
        if "items" and len(data["items"]) > 0:
            return data["items"][0]
        else:
            logger.warning(f"âš ï¸ API: å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ ({video_id})")
            return None
    except Exception as e:
        logger.error(f"âŒ API ã‚¨ãƒ©ãƒ¼: {video_id} - {e}")
        return None


def determine_archive_published_at(details: dict) -> str:
    """
    ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã® published_at ã‚’æ–°ã—ã„ãƒ­ã‚¸ãƒƒã‚¯ã§åˆ¤å®š

    - actualEndTime ã¨ publishedAt ã®ã†ã¡ã€ç¾åœ¨æ™‚åˆ»ã«è¿‘ã„æ–¹ã‚’æ¡ç”¨
    - ã©ã¡ã‚‰ã‹ä¸€æ–¹ã®ã¿ã®å ´åˆã¯ãã‚Œã‚’æ¡ç”¨
    """
    if not details:
        return None

    live_details = details.get("liveStreamingDetails", {})
    snippet = details.get("snippet", {})

    actual_end_time = live_details.get("actualEndTime")
    published_at = snippet.get("publishedAt")

    if actual_end_time and published_at:
        # ç¾åœ¨æ™‚åˆ»ã«æœ€ã‚‚è¿‘ã„æ–¹ã‚’æ¡ç”¨
        try:
            now = datetime.now(timezone.utc)
            end_time_dt = datetime.fromisoformat(actual_end_time.replace('Z', '+00:00'))
            pub_time_dt = datetime.fromisoformat(published_at.replace('Z', '+00:00'))

            end_delta = abs((end_time_dt - now).total_seconds())
            pub_delta = abs((pub_time_dt - now).total_seconds())

            if pub_delta < end_delta:
                logger.debug(f"ğŸ“¡ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–åˆ¤å®š: publishedAt ã‚’æ¡ç”¨ï¼ˆpub_delta={pub_delta}ç§’ < end_delta={end_delta}ç§’ï¼‰")
                return published_at
            else:
                logger.debug(f"ğŸ“¡ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–åˆ¤å®š: actualEndTime ã‚’æ¡ç”¨ï¼ˆend_delta={end_delta}ç§’ <= pub_delta={pub_delta}ç§’ï¼‰")
                return actual_end_time
        except Exception as e:
            logger.debug(f"âš ï¸ æ™‚åˆ»å·®åˆ†è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}ã€publishedAt ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            return published_at or actual_end_time
    elif published_at:
        logger.debug(f"ğŸ“¡ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–åˆ¤å®š: publishedAt ã‚’ä½¿ç”¨ï¼ˆactualEndTime ãªã—ï¼‰")
        return published_at
    elif actual_end_time:
        logger.debug(f"ğŸ“¡ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–åˆ¤å®š: actualEndTime ã‚’ä½¿ç”¨ï¼ˆpublishedAt ãªã—ï¼‰")
        return actual_end_time

    return None


def update_existing_archives():
    """æ—¢å­˜ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ãƒ­ã‚¸ãƒƒã‚¯ã§æ›´æ–°"""
    from plugins.youtube_api_plugin import YouTubeAPIPlugin

    try:
        api_plugin = YouTubeAPIPlugin()
        if not api_plugin.is_available():
            logger.error("âŒ YouTube API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return

        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        # DB ã«ç™»éŒ²æ¸ˆã¿ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’å–å¾—
        cursor.execute("""
            SELECT id, video_id, title, published_at, content_type, live_status
            FROM videos
            WHERE content_type = 'archive'
            ORDER BY published_at DESC
        """)

        archives = cursor.fetchall()
        conn.close()

        logger.info(f"ğŸ“Š å‡¦ç†å¯¾è±¡: {len(archives)} ä»¶ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–")

        updated_count = 0
        skipped_count = 0

        for idx, (db_id, video_id, title, db_published_at, content_type, live_status) in enumerate(archives, 1):
            logger.info(f"\n[{idx}/{len(archives)}] å‡¦ç†ä¸­: {title}")
            logger.info(f"   video_id: {video_id}")
            logger.info(f"   DB ã® published_at: {db_published_at}")

            # API ã‹ã‚‰æœ€æ–°æƒ…å ±ã‚’å–å¾—
            details = get_archive_api_details(video_id, api_plugin.api_key)
            if not details:
                logger.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: API ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
                skipped_count += 1
                continue

            # æ–°ã—ã„ãƒ­ã‚¸ãƒƒã‚¯ã§ published_at ã‚’æ±ºå®š
            api_published_at = determine_archive_published_at(details)
            if not api_published_at:
                logger.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: publishedAt æƒ…å ±ãªã—")
                skipped_count += 1
                continue

            # UTC â†’ JST å¤‰æ›
            api_published_at_jst = convert_utc_to_jst(api_published_at)

            logger.info(f"   API ã® published_at (UTC): {api_published_at}")
            logger.info(f"   API ã® published_at (JST): {api_published_at_jst}")

            # DB ã¨æ¯”è¼ƒ
            if api_published_at_jst != db_published_at:
                logger.info(f"   âœ… æ›´æ–°å¯¾è±¡: {db_published_at} â†’ {api_published_at_jst}")

                # DB ã‚’æ›´æ–°
                try:
                    conn = sqlite3.connect(DB_PATH)
                    cursor = conn.cursor()
                    cursor.execute(
                        "UPDATE videos SET published_at = ? WHERE id = ?",
                        (api_published_at_jst, db_id)
                    )
                    conn.commit()
                    conn.close()

                    logger.info(f"   âœ… DB æ›´æ–°å®Œäº†")
                    updated_count += 1
                except Exception as e:
                    logger.error(f"   âŒ DB æ›´æ–°å¤±æ•—: {e}")
                    skipped_count += 1
            else:
                logger.info(f"   â„¹ï¸ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢ã«åŒã˜å€¤ï¼‰")
                skipped_count += 1

        logger.info(f"\n" + "=" * 80)
        logger.info(f"ğŸ“Š å‡¦ç†å®Œäº†")
        logger.info(f"   âœ… æ›´æ–°: {updated_count} ä»¶")
        logger.info(f"   â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {skipped_count} ä»¶")
        logger.info(f"=" * 80)

    except Exception as e:
        logger.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    logger.info("=" * 80)
    logger.info("ğŸ”„ æ—¢å­˜ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ã®å†æ›´æ–°ã‚’é–‹å§‹ã—ã¾ã™")
    logger.info("=" * 80)
    update_existing_archives()
